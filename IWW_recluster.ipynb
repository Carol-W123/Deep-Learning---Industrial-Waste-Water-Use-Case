{"cells":[{"cell_type":"code","source":["import warnings\n# Squash warning messages\n#warnings.showwarning = lambda *args, **kwargs: None\n\nimport pandas as pd\nimport sklearn\nfrom sklearn import cluster\n# from sklearn import ensemble\n# from sklearn import metrics\n# from sklearn import model_selection\n# from sklearn.metrics import davies_bouldin_score\n\nimport numpy as np\nimport math\nimport time\n\nfrom scipy import stats\n\n# Import the necessary functions for reading iww sql db\nfrom pyspark.sql.functions import *\n\n# Use arrow conversion for spark DF to pandas DF and vice versa\nspark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n\nprint(\"Pandas \", pd.__version__)\nprint(\"Numpy \", np.__version__)\n\n#Importing Pandas\n#Raw_Total_Data = pd.read_cs//v(r\"C:\\Users\\ryan.hagan\\Desktop\\01_Preprocessed_WaterQuality_Data.csv\", encoding = \"ISO-8859-1\")\n                             \n#Raw_Target_Data = pd.read_csv(r\"C:\\Users\\ryan.hagan\\Desktop\\01_Preprocessed_WaterQuality_Data.csv\", encoding = \"ISO-8859-1\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c54aa996-9ea4-4249-887f-21a0068d7f5f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Pandas  0.19.2\nNumpy  1.11.1\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Pandas  0.19.2\nNumpy  1.11.1\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["\n#Reading new IWW Water Quality data table\niww_quality_SDF = spark.read.format(\"jdbc\") \\\n\t.option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\\\n\t.option(\"url\", \"jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005\") \\\n\t.option(\"dbtable\", \"RAW_SAMPLE_DATA\") \\\n\t.option(\"user\", \"ABO_IWWD_Admin\") \\\n\t.option(\"password\",\"!WWD_ad_2019\").load()\n\niww_toxicity_SDF = spark.read.format(\"jdbc\") \\\n\t.option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\\\n\t.option(\"url\", \"jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005\") \\\n\t.option(\"dbtable\", \"RAW_TOXICITY_DATA\") \\\n\t.option(\"user\", \"ABO_IWWD_Admin\") \\\n\t.option(\"password\",\"!WWD_ad_2019\").load()\n\n\n#Using Pandas dataframes with arrow conversion\nRaw_Total_Data = iww_quality_SDF.select(\"*\").toPandas()\nRaw_Target_Data = Raw_Total_Data\nRaw_Toxicity_Data = iww_toxicity_SDF.select(\"*\").toPandas()\n\n\nRaw_Toxicity_Data.drop('Mapsite', axis=1, inplace=True)\nRaw_Toxicity_Data.drop('Outfall_Status', axis=1, inplace=True)\n\n#Raw_Toxicity_Data.head()\n\n\nJoined_water_data=pd.merge(left=Raw_Total_Data, right=Raw_Toxicity_Data, left_on='Sample_Date', right_on='Sample_Date', how='outer' )\n\n\n\n# # Write the Bridge dataframe to a new table in the database\njoined_SDF = spark.createDataFrame(Joined_water_data)\njoined_SDF.write.format(\"jdbc\").mode(\"overwrite\") \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\\\n    .option(\"url\", \"jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005\") \\\n    .option(\"dbtable\", \"RAW_QUALITY_DATA\") \\\n    .option(\"user\", \"ABO_IWWD_Admin\") \\\n    .option(\"password\", \"!WWD_ad_2019\").save()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"055e008b-c0cd-4894-8010-acd94c214a01"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3644325364902747&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansired\">#Reading new IWW Water Quality data table</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>iww_quality_SDF <span class=\"ansiyellow\">=</span> spark<span class=\"ansiyellow\">.</span>read<span class=\"ansiyellow\">.</span>format<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;jdbc&quot;</span><span class=\"ansiyellow\">)</span>     <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;driver&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;</span><span class=\"ansiyellow\">)</span>       <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;url&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005&quot;</span><span class=\"ansiyellow\">)</span>      <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;dbtable&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;RAW_SAMPLE_DATA&quot;</span><span class=\"ansiyellow\">)</span>   <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;user&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;ABO_IWWD_Admin&quot;</span><span class=\"ansiyellow\">)</span>       <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;password&quot;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&quot;!WWD_ad_2019&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>load<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> iww_toxicity_SDF <span class=\"ansiyellow\">=</span> spark<span class=\"ansiyellow\">.</span>read<span class=\"ansiyellow\">.</span>format<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;jdbc&quot;</span><span class=\"ansiyellow\">)</span>    <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;driver&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;</span><span class=\"ansiyellow\">)</span>       <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;url&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005&quot;</span><span class=\"ansiyellow\">)</span>      <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;dbtable&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;RAW_TOXICITY_DATA&quot;</span><span class=\"ansiyellow\">)</span>         <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;user&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;ABO_IWWD_Admin&quot;</span><span class=\"ansiyellow\">)</span>       <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;password&quot;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&quot;!WWD_ad_2019&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>load<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansicyan\">load</span><span class=\"ansiblue\">(self, path, format, schema, **options)</span>\n<span class=\"ansigreen\">    170</span>             <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_df<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jreader<span class=\"ansiyellow\">.</span>load<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_spark<span class=\"ansiyellow\">.</span>_sc<span class=\"ansiyellow\">.</span>_jvm<span class=\"ansiyellow\">.</span>PythonUtils<span class=\"ansiyellow\">.</span>toSeq<span class=\"ansiyellow\">(</span>path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    171</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 172</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_df<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jreader<span class=\"ansiyellow\">.</span>load<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    173</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    174</span>     <span class=\"ansiyellow\">@</span>since<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">1.4</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    327</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 328</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    329</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    330</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o264.load.\n: com.microsoft.sqlserver.jdbc.SQLServerException: Database &apos;edsqutarmsqluw2005&apos; on server &apos;sqlqutarmsvruw2003.database.windows.net&apos; is not currently available.  Please retry the connection later.  If the problem persists, contact customer support, and provide them the session tracing ID of &apos;{BB580F67-5B9E-4DB9-A467-DB4BCB5BA171}&apos;. ClientConnectionId:759c9207-b6c4-4cb3-b7b4-4f6bfcbaa60a\n\tat com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:258)\n\tat com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:256)\n\tat com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:108)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.sendLogon(SQLServerConnection.java:4290)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.logon(SQLServerConnection.java:3157)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.access$100(SQLServerConnection.java:82)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection$LogonCommand.doExecute(SQLServerConnection.java:3121)\n\tat com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7151)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:2478)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connectHelper(SQLServerConnection.java:2026)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.login(SQLServerConnection.java:1687)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connectInternal(SQLServerConnection.java:1528)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connect(SQLServerConnection.java:866)\n\tat com.microsoft.sqlserver.jdbc.SQLServerDriver.connect(SQLServerDriver.java:569)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$createConnectionFactory$1.apply(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$createConnectionFactory$1.apply(JdbcUtils.scala:55)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:56)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:210)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:35)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:291)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:277)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:201)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>","errorSummary":"com.microsoft.sqlserver.jdbc.SQLServerException: Database &apos;edsqutarmsqluw2005&apos; on server &apos;sqlqutarmsvruw2003.database.windows.net&apos; is not currently available.  Please retry the connection later.  If the problem persists, contact customer support, and provide them the session tracing ID of &apos;{BB580F67-5B9E-4DB9-A467-DB4BCB5BA171}&apos;. ClientConnectionId:759c9207-b6c4-4cb3-b7b4-4f6bfcbaa60a","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3644325364902747&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansired\">#Reading new IWW Water Quality data table</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>iww_quality_SDF <span class=\"ansiyellow\">=</span> spark<span class=\"ansiyellow\">.</span>read<span class=\"ansiyellow\">.</span>format<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;jdbc&quot;</span><span class=\"ansiyellow\">)</span>     <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;driver&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;</span><span class=\"ansiyellow\">)</span>       <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;url&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005&quot;</span><span class=\"ansiyellow\">)</span>      <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;dbtable&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;RAW_SAMPLE_DATA&quot;</span><span class=\"ansiyellow\">)</span>   <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;user&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;ABO_IWWD_Admin&quot;</span><span class=\"ansiyellow\">)</span>       <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;password&quot;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&quot;!WWD_ad_2019&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>load<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> iww_toxicity_SDF <span class=\"ansiyellow\">=</span> spark<span class=\"ansiyellow\">.</span>read<span class=\"ansiyellow\">.</span>format<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;jdbc&quot;</span><span class=\"ansiyellow\">)</span>    <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;driver&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;</span><span class=\"ansiyellow\">)</span>       <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;url&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005&quot;</span><span class=\"ansiyellow\">)</span>      <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;dbtable&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;RAW_TOXICITY_DATA&quot;</span><span class=\"ansiyellow\">)</span>         <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;user&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;ABO_IWWD_Admin&quot;</span><span class=\"ansiyellow\">)</span>       <span class=\"ansiyellow\">.</span>option<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;password&quot;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&quot;!WWD_ad_2019&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>load<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansicyan\">load</span><span class=\"ansiblue\">(self, path, format, schema, **options)</span>\n<span class=\"ansigreen\">    170</span>             <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_df<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jreader<span class=\"ansiyellow\">.</span>load<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_spark<span class=\"ansiyellow\">.</span>_sc<span class=\"ansiyellow\">.</span>_jvm<span class=\"ansiyellow\">.</span>PythonUtils<span class=\"ansiyellow\">.</span>toSeq<span class=\"ansiyellow\">(</span>path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    171</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 172</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_df<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jreader<span class=\"ansiyellow\">.</span>load<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    173</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    174</span>     <span class=\"ansiyellow\">@</span>since<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">1.4</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    327</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 328</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    329</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    330</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o264.load.\n: com.microsoft.sqlserver.jdbc.SQLServerException: Database &apos;edsqutarmsqluw2005&apos; on server &apos;sqlqutarmsvruw2003.database.windows.net&apos; is not currently available.  Please retry the connection later.  If the problem persists, contact customer support, and provide them the session tracing ID of &apos;{BB580F67-5B9E-4DB9-A467-DB4BCB5BA171}&apos;. ClientConnectionId:759c9207-b6c4-4cb3-b7b4-4f6bfcbaa60a\n\tat com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:258)\n\tat com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:256)\n\tat com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:108)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.sendLogon(SQLServerConnection.java:4290)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.logon(SQLServerConnection.java:3157)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.access$100(SQLServerConnection.java:82)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection$LogonCommand.doExecute(SQLServerConnection.java:3121)\n\tat com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7151)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:2478)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connectHelper(SQLServerConnection.java:2026)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.login(SQLServerConnection.java:1687)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connectInternal(SQLServerConnection.java:1528)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connect(SQLServerConnection.java:866)\n\tat com.microsoft.sqlserver.jdbc.SQLServerDriver.connect(SQLServerDriver.java:569)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$createConnectionFactory$1.apply(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$createConnectionFactory$1.apply(JdbcUtils.scala:55)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:56)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:210)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:35)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:291)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:277)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:201)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Forcing data to be float\nRaw_Total_Data.iloc[:, 1:] = Raw_Total_Data.iloc[:, 1:].apply(pd.to_numeric, downcast='float', errors='coerce').astype(float)\nfor data in Raw_Total_Data.columns[Raw_Total_Data.isna().any()].tolist():\n  for i, row in Raw_Total_Data.iterrows():\n    val = Raw_Total_Data.at[i, data]\n    if math.isnan(val):\n      print(\"Column: \" + data)\n      print(\"Index: \" + str(i))\nCleaned_Total_Data = Raw_Total_Data.iloc[:,1:].dropna()\n\nRaw_Target_Data.iloc[:, 1:] = Raw_Target_Data.iloc[:, 1:].apply(pd.to_numeric, downcast = 'float', errors = 'coerce').astype(float)\nCleaned_Target_Data = Raw_Target_Data.iloc[:,1:].dropna()\n\nn_features = Cleaned_Total_Data.shape[1]\nn_samples = Cleaned_Total_Data.shape[0]\n\nprint('Total number of features: ', str(n_features))\nprint('Total number of samples: ', str(n_samples))\n\nDates = Raw_Target_Data['Sample_Date']\nDates.columns = ['Sample_Date']\ndropped_values = Dates.shape[0] - Cleaned_Target_Data.shape[0]\n\n#Backlog item... oldest date values are currently dropped. If all values are correctly formatted (ie once integration is complete) no dates will be dropped\nDates = Dates.iloc[(dropped_values):]\n\n# Dates.head"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f336d821-7bdc-40f2-98e4-6b92f7b7fc71"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Column: Antimony_mg_L\nIndex: 27\nColumn: Barium_mg_L\nIndex: 27\nColumn: Beryllium_mg_L\nIndex: 27\nColumn: Cadmium_g_L\nIndex: 27\nColumn: Chromium_mg_L\nIndex: 27\nColumn: Iron_mg_L\nIndex: 27\nColumn: Lead_mg_L\nIndex: 27\nColumn: Lithium_mg_L\nIndex: 27\nColumn: Molybdenum_mg_L\nIndex: 27\nColumn: Nickel_mg_L\nIndex: 27\nColumn: Selenium_mg_L\nIndex: 27\nColumn: Silver_mg_L\nIndex: 27\nColumn: Thallium_mg_L\nIndex: 27\nColumn: Uranium_mg_L\nIndex: 27\nColumn: Vanadium_mg_L\nIndex: 27\nColumn: Zinc_mg_L\nIndex: 27\nColumn: Aluminum_Dissolved_mg_L\nIndex: 27\nTotal number of features:  82\nTotal number of samples:  235\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Column: Antimony_mg_L\nIndex: 27\nColumn: Barium_mg_L\nIndex: 27\nColumn: Beryllium_mg_L\nIndex: 27\nColumn: Cadmium_g_L\nIndex: 27\nColumn: Chromium_mg_L\nIndex: 27\nColumn: Iron_mg_L\nIndex: 27\nColumn: Lead_mg_L\nIndex: 27\nColumn: Lithium_mg_L\nIndex: 27\nColumn: Molybdenum_mg_L\nIndex: 27\nColumn: Nickel_mg_L\nIndex: 27\nColumn: Selenium_mg_L\nIndex: 27\nColumn: Silver_mg_L\nIndex: 27\nColumn: Thallium_mg_L\nIndex: 27\nColumn: Uranium_mg_L\nIndex: 27\nColumn: Vanadium_mg_L\nIndex: 27\nColumn: Zinc_mg_L\nIndex: 27\nColumn: Aluminum_Dissolved_mg_L\nIndex: 27\nTotal number of features:  82\nTotal number of samples:  235\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["\nimport warnings\n# Squash warning messages\nwarnings.showwarning = lambda *args, **kwargs: None\n\n#This is a robust clustering algorithm used to detect outliers\nBirch_Output_System = sklearn.cluster.Birch(n_clusters=2, compute_labels=True, copy=True).fit_predict(Cleaned_Total_Data)\n# Birch_Output_System3 = sklearn.cluster.Birch(n_clusters=3, compute_labels=True, copy=True).fit_predict(Cleaned_Total_Data)\n\n#Applying to one data stream at a time\nBirch_Output_Individual_Stream = Cleaned_Total_Data.copy()\n# Birch_Output_Individual_Stream3 = Cleaned_Total_Data.copy()\n\nfor Counter in range(0, Cleaned_Total_Data.shape[1]):\n    Input_Array = Cleaned_Total_Data.iloc[:,Counter].values\n    Birch_Output_Individual_Stream.iloc[:, Counter] = sklearn.cluster.Birch(n_clusters=2, compute_labels=True, copy=True).fit_predict(Input_Array.reshape(-1,1))\n#     Birch_Output_Individual_Stream3.iloc[:, Counter] = sklearn.cluster.Birch(n_clusters=3, compute_labels=True, copy=True).fit_predict(Input_Array.reshape(-1,1))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8b620d4c-f1ed-4431-a37d-84c9d7dcaa94"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Third algorithm is agglomorative clustering\n#Applying to the whole system\nAggCluster_Output_System = sklearn.cluster.AgglomerativeClustering(n_clusters=2, affinity='euclidean', compute_full_tree='auto', linkage='ward').fit_predict(Cleaned_Total_Data)\n\n#Applying to one data stream at a time\nAggCluster_Output_Individual_Stream = Cleaned_Total_Data.copy()\nfor Counter in range(0, Cleaned_Total_Data.shape[1]):\n    Input_Array = Cleaned_Total_Data.iloc[:,Counter].values\n    AggCluster_Output_Individual_Stream.iloc[:, Counter] = sklearn.cluster.AgglomerativeClustering(n_clusters=2, affinity='euclidean', compute_full_tree='auto', linkage='ward').fit_predict(Input_Array.reshape(-1,1))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f26ddd1c-d783-49a1-a0a8-e97db646dfc5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Applying the ensembling algoritm\n\n#Analyzing overall system state\n#First agglomerating features\nEnsemble_System_Input = np.zeros((int(AggCluster_Output_System.shape[0]),3))\nEnsemble_System_Input[:,0] = AggCluster_Output_System\nEnsemble_System_Input[:,1] = Birch_Output_System\nEnsemble_System_TempStorage = sklearn.cluster.FeatureAgglomeration(n_clusters=2, affinity='euclidean', \n                                                              compute_full_tree='auto', linkage='ward').fit_transform(Ensemble_System_Input)\n#Then applying clustering\nEnsemble_Output_System = sklearn.cluster.AgglomerativeClustering(n_clusters=2, affinity='euclidean', compute_full_tree='auto', linkage='ward').fit_predict(Ensemble_System_TempStorage)\n\n#Analyzing Individual Data Streams\nEnsemble_Output_Individual_Stream = Cleaned_Total_Data.copy()\nfor Counter in range(0, Cleaned_Total_Data.shape[1]):\n    Ensemble_Input_Individual_Stream = np.zeros((int(AggCluster_Output_System.shape[0]),3))\n    Ensemble_Input_Individual_Stream[:,0] = AggCluster_Output_Individual_Stream.iloc[:,Counter].values\n    Ensemble_Input_Individual_Stream[:,1] = Birch_Output_Individual_Stream.iloc[:,Counter].values\n    Ensemble_Individual_Stream_TempStorage = sklearn.cluster.FeatureAgglomeration(n_clusters=2, affinity='euclidean', \n                                                                       compute_full_tree='auto', linkage='ward').fit_transform(Ensemble_Input_Individual_Stream)\n    Ensemble_Output_Individual_Stream.iloc[:, Counter] = sklearn.cluster.AgglomerativeClustering(n_clusters=2, affinity='euclidean', compute_full_tree='auto', linkage='ward').fit_predict(Ensemble_Individual_Stream_TempStorage)\n\n\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d5025375-0733-4aa4-9d04-8aba315a1c9e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Metrics calculations for debugging and/or experimenting\n\n# EnsembleModel_Silhoutte = metrics.silhouette_score(Cleaned_Total_Data, Ensemble_Output_System, metric='euclidean')\n# Aggcluster_Silhoutte = metrics.silhouette_score(Cleaned_Total_Data, AggCluster_Output_System, metric='euclidean')\n# Birch_Silhoutte = metrics.silhouette_score(Cleaned_Total_Data, Birch_Output_System, metric='euclidean')\n# EnsembleModel_db = metrics.davies_bouldin_score(Cleaned_Total_Data, Ensemble_Output_System)\n# Aggcluster_db = metrics.davies_bouldin_score(Cleaned_Total_Data, AggCluster_Output_System)\n# Birch_db = metrics.davies_bouldin_score(Cleaned_Total_Data, Birch_Output_System)\n\n# print(Aggcluster_db)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f43bdf9-9667-427e-8f48-5d84484f1bf8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Saving the results of Anomaly Detection Algorithm\n#These options are left here in case a different approach is decided upon later\n# Ensemble_Output_System_Dataframe = pd.DataFrame(data= Ensemble_Output_System, index = Cleaned_Total_Data.index.values)\n# Birch_Output_System_Dataframe = pd.DataFrame(data= Birch_Output_System, index = Cleaned_Total_Data.index.values)\n# Ensemble_Output_Individual_Stream_Dataframe = pd.DataFrame(data= Ensemble_Output_Individual_Stream, index = Cleaned_Total_Data.index.values,\n#                                     columns = Cleaned_Total_Data.columns.values)\n\n\n# Birch_Output_Individual_Stream_Dataframe = pd.DataFrame(data= Birch_Output_Individual_Stream, index = Cleaned_Total_Data.index.values,\n#                                     columns = Cleaned_Total_Data.columns.values)\n\n\nAgg_Output_System_Dataframe = pd.DataFrame(data= AggCluster_Output_System, index = Cleaned_Total_Data.index.values)\n\nAgg_Output_Individual_Stream_Dataframe = pd.DataFrame(data= AggCluster_Output_Individual_Stream, index = Cleaned_Total_Data.index.values,\n                                    columns = Cleaned_Total_Data.columns.values)\n\n\n#Title overall system cluster output as system status\nAgg_Output_System_Dataframe.columns = ['System_Status']\n\n#Append the dates and two output clusters horizontally (axis 1 not 0)\nAgg_Output_All = pd.concat([Dates, Agg_Output_System_Dataframe, Agg_Output_Individual_Stream_Dataframe], axis=1)\nAgg_Output_All = Agg_Output_All.dropna()\n\n# Agg_Output_All.head()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4836fe5-5e9a-4633-9c44-cc1d4bcbb9d4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Go through each column, invert value if the clustering is inverted\n# rows is the total number of tests in the set\n# the values in each column are 1 or 0\n# if the sum of the values in each column are less than 1/2(rows)\n# flip the 1's and 0's\nhalf_point = 0.5 * len(Agg_Output_All)\n\n# Run on every column except the date column\nfor col in Agg_Output_All.columns[1:]:\n  if Agg_Output_All[col].sum() < half_point:\n    for i, row in Agg_Output_All.iterrows():\n      val = Agg_Output_All.at[i, col]\n      if val == 0:\n        Agg_Output_All.at[i, col] = 1\n      elif val == 1:\n        Agg_Output_All.at[i, col] = 0\n        "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"682661e2-ddfa-48c9-bf65-953ef93f6f0c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#convert final results back to Spark dataframe\nAgg_Output_SDF = spark.createDataFrame(Agg_Output_All)\n\n# Writing results to IWW Tag Value table for powerBI ingestion\nAgg_Output_SDF.write.format(\"jdbc\").mode(\"overwrite\") \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\\\n    .option(\"url\", \"jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005\") \\\n    .option(\"dbtable\", \"ANOMALY_CLUSTERS\") \\\n    .option(\"user\", \"ABO_IWWD_Admin\") \\\n    .option(\"password\", \"!WWD_ad_2019\").save()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"101a5c34-7bc0-40ce-921b-dae10670a132"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"Agg_Output_SDF","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Sample_Date","nullable":true,"type":"date"},{"metadata":{},"name":"System_Status","nullable":true,"type":"double"},{"metadata":{},"name":"Total_Alkalinity_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Conductivity_S_cm","nullable":true,"type":"double"},{"metadata":{},"name":"DIC_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"DOC_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Hardness_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"TDS_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Mercury_Total_ng_L","nullable":true,"type":"double"},{"metadata":{},"name":"Mercury_Dissolved_ng_L","nullable":true,"type":"double"},{"metadata":{},"name":"Chromium_Hexavalent_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Cyanide_Weak_Acid_Dissociable_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Cyanide_Total_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Naphthenic_Acids_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"F1_C6_C10_g_L","nullable":true,"type":"double"},{"metadata":{},"name":"F2_C10_C16_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"F3_C16_C34_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"F4_C34_C50_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Calcium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Chloride_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Magnesium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Potassium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Sulfate_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Sodium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Nitrate_Nitrite_as_N_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Total_Kjeldahl_Nitrogen_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Total_Nitrogen_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Phosphorus_Total_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Phosphorus_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Ammonia_as_N_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Aluminum_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Antimony_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Arsenic_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Barium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Beryllium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Bismuth_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Boron_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Cadmium_g_L","nullable":true,"type":"double"},{"metadata":{},"name":"Chromium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Cobalt_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Copper_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Iron_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Lead_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Lithium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Manganese_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Molybdenum_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Nickel_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Selenium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Silver_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Strontium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Thallium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Thorium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Tin_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Titanium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Uranium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Vanadium_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Zinc_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Aluminum_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Antimony_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Arsenic_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Barium_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Beryllium_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Bismuth_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Boron_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Cadmium_Dissolved_g_L","nullable":true,"type":"double"},{"metadata":{},"name":"Chromium_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Cobalt_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Copper_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Iron_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Lead_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Lithium_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Manganese_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Molybdenum_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Nickel_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Selenium_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Silver_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Stontium_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Thallium_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Thorium_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Tin_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Titanium_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Uranium_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Vanadium_Dissolved_mg_L","nullable":true,"type":"double"},{"metadata":{},"name":"Zinc_Dissolved_mg_L","nullable":true,"type":"double"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Iterate through each row of the dataframe\n# Calculate TP, TN, FP, FN, Sensitivity, Specificity\n# Sensitivity = TP / TP + FN\n# Specificity = TN / FP + TN\n# Add calulcated values to a new table with format:\n#\n# Test Type        TP      TN      FP        FN      Sens         Spec\n# Total Alkalinity\n# Conductivity\n# .......\nrows = len(Agg_Output_All)\ntests = Agg_Output_All.columns[2:]\nblanks = [0.0] * len(tests)\n\ndata = {'Tests': tests,\n       'True Positive': blanks,\n       'True Positive %': blanks,\n       'True Negative': blanks,\n       'True Negative %': blanks,\n       'False Positive': blanks,\n       'False Positive %': blanks,\n       'False Negative': blanks,\n       'False Negative %': blanks,\n       'Sensitivity': blanks,\n       'Sensitivity Rank': blanks,\n       'Specificity': blanks,\n       'Specificity Rank': blanks}\nalg_accuracy = pd.DataFrame(data)\n\nctr = 0\nfor col in Agg_Output_All.columns[2:]:\n  tp = 0\n  tn = 0\n  fp = 0\n  fn = 0\n  # sum up the tp, tn, fp, and fn for each row\n  for i, row in Agg_Output_All.iterrows():\n    sys_status = Agg_Output_All.at[i, 'System_Status']\n    el_status = Agg_Output_All.at[i, col]\n    if sys_status == 1 and el_status == 1:\n      tp += 1\n    elif sys_status == 0 and el_status == 0:\n      tn += 1\n    elif sys_status == 0 and el_status == 1:\n      fp += 1\n    elif sys_status == 1 and el_status == 0:\n      fn += 1\n  \n  # assign values to the alg_accuracy dataframe\n  alg_accuracy.at[ctr, 'True Positive'] = tp\n  alg_accuracy.at[ctr, 'True Positive %'] = float(tp / rows) * 100.0\n  alg_accuracy.at[ctr, 'True Negative'] = tn\n  alg_accuracy.at[ctr, 'True Negative %'] = float(tn / rows) * 100.0\n  alg_accuracy.at[ctr, 'False Positive'] = fp\n  alg_accuracy.at[ctr, 'False Positive %'] = float(fp / rows) * 100.0\n  alg_accuracy.at[ctr, 'False Negative'] = fn\n  alg_accuracy.at[ctr, 'False Negative %'] = float(fn / rows) * 100.0\n\n  alg_accuracy.at[ctr, 'Sensitivity'] = float(tp) / float(tp + fn) * 100.0\n  alg_accuracy.at[ctr, 'Specificity'] = float(tn) / float(fp + tn) * 100.0\n  \n  ctr += 1\n\n# Get the ranking of sensitivity and specificity for each element\nsens_rank = len(alg_accuracy['Sensitivity']) - stats.rankdata(alg_accuracy['Sensitivity'], method='max')\nspec_rank = len(alg_accuracy['Specificity']) - stats.rankdata(alg_accuracy['Specificity'], method='max')\nfor i, row in alg_accuracy.iterrows():\n  alg_accuracy.at[i, 'Sensitivity Rank'] = sens_rank[i]\n  alg_accuracy.at[i, 'Specificity Rank'] = spec_rank[i]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa8a2b72-67ca-409b-8679-4607aaecd956"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["cols = alg_accuracy.columns[1:]\nalg_accuracy[cols] = alg_accuracy[cols].apply(pd.to_numeric, downcast = 'float', errors = 'coerce')\n\n#convert final results back to Spark dataframe\nalg_accuracy_SDF = spark.createDataFrame(alg_accuracy)\n\n# Writing results to IWW Tag Value table for powerBI ingestion\nalg_accuracy_SDF.write.format(\"jdbc\").mode(\"overwrite\") \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\\\n    .option(\"url\", \"jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005\") \\\n    .option(\"dbtable\", \"ALGORITHM_ACCURACY\") \\\n    .option(\"user\", \"ABO_IWWD_Admin\") \\\n    .option(\"password\", \"!WWD_ad_2019\").save()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bea625db-dedb-4338-9f22-5490988d4b30"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"alg_accuracy_SDF","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Tests","nullable":true,"type":"string"},{"metadata":{},"name":"True Positive","nullable":true,"type":"float"},{"metadata":{},"name":"True Positive %","nullable":true,"type":"float"},{"metadata":{},"name":"True Negative","nullable":true,"type":"float"},{"metadata":{},"name":"True Negative %","nullable":true,"type":"float"},{"metadata":{},"name":"False Positive","nullable":true,"type":"float"},{"metadata":{},"name":"False Positive %","nullable":true,"type":"float"},{"metadata":{},"name":"False Negative","nullable":true,"type":"float"},{"metadata":{},"name":"False Negative %","nullable":true,"type":"float"},{"metadata":{},"name":"Sensitivity","nullable":true,"type":"float"},{"metadata":{},"name":"Sensitivity Rank","nullable":true,"type":"float"},{"metadata":{},"name":"Specificity","nullable":true,"type":"float"},{"metadata":{},"name":"Specificity Rank","nullable":true,"type":"float"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create an Attribute Table\n# Get the types of elemental tests that are run, remove the date column\ncluster_type = list(Agg_Output_All)\ncluster_type.remove('Sample_Date')\n\n# Write the test types to a dataframe\nclustering_type_dataframe = pd.DataFrame(data=cluster_type, columns=['Clustering Category'])\n# clustering_type_dataframe.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32e551f9-c51b-48a6-b913-b1ae64dbcebd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Write the Test Type dataframe to a new table in the database\niww_clustering_types_SDF = spark.createDataFrame(clustering_type_dataframe)\niww_clustering_types_SDF.write.format(\"jdbc\").mode(\"overwrite\") \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\\\n    .option(\"url\", \"jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005\") \\\n    .option(\"dbtable\", \"CLUSTERING_TYPE\") \\\n    .option(\"user\", \"ABO_IWWD_Admin\") \\\n    .option(\"password\", \"!WWD_ad_2019\").save()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"11a07c9f-43ad-4f2c-b12e-748ab350e053"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"iww_clustering_types_SDF","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Clustering Category","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create a Bridge Table\nbridge = pd.melt(Agg_Output_All,\n                    id_vars=['Sample_Date'],\n                    value_vars=cluster_type,\n                    var_name='Attribute',\n                    value_name='Value')\n\nbridge['Value'] = bridge['Value'].apply(pd.to_numeric, downcast='float', errors='coerce').astype(float)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3aa7f54f-1a35-4430-9ef4-4c493c2d62f5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Write the Bridge dataframe to a new table in the database\niww_bridge_SDF = spark.createDataFrame(bridge)\niww_bridge_SDF.write.format(\"jdbc\").mode(\"overwrite\") \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\\\n    .option(\"url\", \"jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005\") \\\n    .option(\"dbtable\", \"CLUSTERING_TYPE_BRIDGE\") \\\n    .option(\"user\", \"ABO_IWWD_Admin\") \\\n    .option(\"password\", \"!WWD_ad_2019\").save()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f7dfa33-ca05-41a0-9645-722e6aa4eca1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"iww_bridge_SDF","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Sample_Date","nullable":true,"type":"date"},{"metadata":{},"name":"Attribute","nullable":true,"type":"string"},{"metadata":{},"name":"Value","nullable":true,"type":"double"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# #Reading Toxicity data table\n# toxicity_data_SDF = spark.read.format(\"jdbc\") \\\n# \t.option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\\\n# \t.option(\"url\", \"jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005\") \\\n# \t.option(\"dbtable\", \"dbo.TOXICITY_DATA$\") \\\n# \t.option(\"user\", \"ABO_IWWD_Admin\") \\\n# \t.option(\"password\",\"!WWD_ad_2019\").load()\n\n# #Using Pandas dataframes with arrow conversion\n# toxicity_data = toxicity_data_SDF.select(\"*\").toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f72188b8-19af-47e7-9528-609ed3378c57"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# print(toxicity_data['Sample Date'])\n# cols = toxicity_data.columns[3:]\n# toxicity_data[cols] = toxicity_data[cols].apply(pd.to_numeric, downcast = 'float', errors = 'coerce')\n# print(toxicity_data['Sample Date'])\n\n# #convert final results back to Spark dataframe\n# toxicity_data_SDF = spark.createDataFrame(toxicity_data)\n\n# # Writing results to IWW Tag Value table for powerBI ingestion\n# toxicity_data_SDF.write.format(\"jdbc\").mode(\"overwrite\") \\\n#     .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\\\n#     .option(\"url\", \"jdbc:sqlserver://sqlqutarmsvruw2003.database.windows.net;databaseName=edsqutarmsqluw2005\") \\\n#     .option(\"dbtable\", \"TOXICITY_DATA\") \\\n#     .option(\"user\", \"ABO_IWWD_Admin\") \\\n#     .option(\"password\", \"!WWD_ad_2019\").save()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ebd630ce-ce2b-492b-b685-b8059facd9ce"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"IWW_recluster","dashboards":[],"language":"python","widgets":{},"notebookOrigID":3644325364902737}},"nbformat":4,"nbformat_minor":0}
